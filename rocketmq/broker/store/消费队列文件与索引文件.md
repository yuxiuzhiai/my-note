# 概念

我们知道，在rocketmq中，每当broker接收到消息，要先往commitlog中写入消息（不一定是写入到物理文件commitLog中，也有可能是对应的MappedFile中），写入成功后，然后给生产者返回，才算是消息生产成功了。由于commitlog是不区分topic的，那消费者如何知道消费哪个呢？答案是consumequeue文件夹。当commitlog存储消息成功后，会将消息转发给DefaultMessageStore$ReputMessageService，ReputMessageService负责将消息写入到对应的消费者队列文件，这样，消费者才能真正的感知到这条消息，然后进行消费。另外，为了可以根据消息的key快速找到消息在commitlog中的位置，rocketmq还专门有一个index文件(其实是一个文件夹)，用于根据消息的key建立索引，以方便后续查找消息。

写到这里，大家要知道，既然consumequeue和index是根据commitlog异步更新的，那必然有种可能是commitlog已经更新了，但是consumequeue和index文件还没更新，如果这样，则这条在生产者看来已经成功写入的消息，就永远无法被消费者消费，那rocketmq是如何解决这个问题的呢？请看下面的分析。

# 组件

## ConsumeQueue

在rocketmq中，消费者队列的概念对应ConsumeQueue类。

## index



## CommitLogDispatcher

```java
public interface CommitLogDispatcher {
  void dispatch(final DispatchRequest request);
}
```

当commitlog写入一条消息后，需要将这条消息的写入通知到其他各方，这个各方就是实现了CommitLogDispatcher的各方。目前，rocketmq中实现了CommitLogDispatcher接口的有三个：

* CommitLogDispatcherCalcBitMap

* DefaultMessageStore$CommitLogDispatcherBuildConsumeQueue:用于消费队列文件的写入

* DefaultMessageStore$CommitLogDispatcherBuildIndex:用于索引文件的写入





# 实现

## ConsumeQueue的更新

hahah

hahhah

```java
private boolean putMessagePositionInfo(final long offset, final int size, final long tagsCode,final long cqOffset) {

  this.byteBufferIndex.flip();
  this.byteBufferIndex.limit(CQ_STORE_UNIT_SIZE);
  this.byteBufferIndex.putLong(offset);
  this.byteBufferIndex.putInt(size);
  this.byteBufferIndex.putLong(tagsCode);

  final long expectLogicOffset = cqOffset * CQ_STORE_UNIT_SIZE;

  MappedFile mappedFile = this.mappedFileQueue.getLastMappedFile(expectLogicOffset);
  if (mappedFile != null) {

    if (mappedFile.isFirstCreateInQueue() && cqOffset != 0 && mappedFile.getWrotePosition() == 0) {
      this.minLogicOffset = expectLogicOffset;
      this.mappedFileQueue.setFlushedWhere(expectLogicOffset);
      this.mappedFileQueue.setCommittedWhere(expectLogicOffset);
      this.fillPreBlank(mappedFile, expectLogicOffset);
      log.info("fill pre blank space " + mappedFile.getFileName() + " " + expectLogicOffset + " "
               + mappedFile.getWrotePosition());
    }

    if (cqOffset != 0) {
      long currentLogicOffset = mappedFile.getWrotePosition() + mappedFile.getFileFromOffset();

      if (expectLogicOffset < currentLogicOffset) {
        log.warn("Build  consume queue repeatedly, expectLogicOffset: {} currentLogicOffset: {} Topic: {} QID: {} Diff: {}",
                 expectLogicOffset, currentLogicOffset, this.topic, this.queueId, expectLogicOffset - currentLogicOffset);
        return true;
      }

      if (expectLogicOffset != currentLogicOffset) {
        LOG_ERROR.warn(
          "[BUG]logic queue order maybe wrong, expectLogicOffset: {} currentLogicOffset: {} Topic: {} QID: {} Diff: {}",
          expectLogicOffset,
          currentLogicOffset,
          this.topic,
          this.queueId,
          expectLogicOffset - currentLogicOffset
        );
      }
    }
    this.maxPhysicOffset = offset + size;
    return mappedFile.appendMessage(this.byteBufferIndex.array());
  }
  return false;
}
```

## index的更新

CommitLogDispatcherBuildIndex并没有具体实现索引文件的更新，而是委托给了IndexService来完成具体操作。入口方法如下：

```java
public void buildIndex(DispatchRequest req) {
  IndexFile indexFile = retryGetAndCreateIndexFile();
  if (indexFile != null) {
    long endPhyOffset = indexFile.getEndPhyOffset();
    DispatchRequest msg = req;
    String topic = msg.getTopic();
    String keys = msg.getKeys();
    if (msg.getCommitLogOffset() < endPhyOffset) {
      return;
    }

    final int tranType = MessageSysFlag.getTransactionValue(msg.getSysFlag());
    switch (tranType) {
      case MessageSysFlag.TRANSACTION_NOT_TYPE:
      case MessageSysFlag.TRANSACTION_PREPARED_TYPE:
      case MessageSysFlag.TRANSACTION_COMMIT_TYPE:
        break;
      case MessageSysFlag.TRANSACTION_ROLLBACK_TYPE:
        return;
    }

    if (req.getUniqKey() != null) {
      indexFile = putKey(indexFile, msg, buildKey(topic, req.getUniqKey()));
      if (indexFile == null) {
        log.error("putKey error commitlog {} uniqkey {}", req.getCommitLogOffset(), req.getUniqKey());
        return;
      }
    }

    if (keys != null && keys.length() > 0) {
      String[] keyset = keys.split(MessageConst.KEY_SEPARATOR);
      for (int i = 0; i < keyset.length; i++) {
        String key = keyset[i];
        if (key.length() > 0) {
          indexFile = putKey(indexFile, msg, buildKey(topic, key));
          if (indexFile == null) {
            log.error("putKey error commitlog {} uniqkey {}", req.getCommitLogOffset(), req.getUniqKey());
            return;
          }
        }
      }
    }
  } else {
    log.error("build index error, stop building index");
  }
}
```

## 异常恢复机制

这里的实现，就是commitlog和consumequeue、index保证最终一致性的关键。

在broker启动的时候，有一个判断abort文件是否存在的过程

```java
public boolean load() {
  boolean result = true;

  try {
    boolean lastExitOK = !this.isTempFileExist();
    log.info("last shutdown {}", lastExitOK ? "normally" : "abnormally");

    if (null != scheduleMessageService) {
      result = result && this.scheduleMessageService.load();
    }

    // load Commit Log
    result = result && this.commitLog.load();

    // load Consume Queue
    result = result && this.loadConsumeQueue();

    if (result) {
      this.storeCheckpoint =
        new StoreCheckpoint(StorePathConfigHelper.getStoreCheckpoint(this.messageStoreConfig.getStorePathRootDir()));

      this.indexService.load(lastExitOK);

      this.recover(lastExitOK);

      log.info("load over, and the max phy offset = {}", this.getMaxPhyOffset());
    }
  } catch (Exception e) {
    log.error("load exception", e);
    result = false;
  }

  if (!result) {
    this.allocateMappedFileService.shutdown();
  }

  return result;
}
```



# 结语



(水平有限，最近在看rocketmq源码，记录学习过程，也希望对各位有点微小的帮助。如有错误，请指正~)

